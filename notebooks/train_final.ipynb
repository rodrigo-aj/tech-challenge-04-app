{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Iniciando Pipeline de Treinamento (XGBoost)...\n",
      ">>> Executando Engenharia de Features...\n",
      ">>> Treinando modelo com 100% dos dados e features...\n",
      ">>> Gerando arquivo de previsões para conferência...\n",
      ">>> Concluído! Arquivos gerados:\n",
      "    - c:\\dev\\pos\\tech-challenge-04\\tech-challenge-04-app\\models\\modelo_obesidade.pkl (Pipeline Completo)\n",
      "    - c:\\dev\\pos\\tech-challenge-04\\tech-challenge-04-app\\models\\encoder_classes.pkl (Tradutor de Classes)\n",
      "    - c:\\dev\\pos\\tech-challenge-04\\tech-challenge-04-app\\data\\historico_predicoes_treino.csv (Tabela com resultados e validação)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pathlib import Path\n",
    "\n",
    "\"\"\"\n",
    "DOCUMENTAÇÃO DA VARIÁVEL ALVO (TARGET)\n",
    "--------------------------------------\n",
    "O modelo foi treinado para realizar uma classificação multiclasse na variável 'Obesity'.\n",
    "As classes representam os diferentes graus de classificação do Índice de Massa Corporal (IMC)\n",
    "e dividem-se em 7 categorias distintas, conforme identificado nos dados de treino:\n",
    "\n",
    "1. Insufficient_Weight  (Abaixo do Peso)\n",
    "2. Normal_Weight        (Peso Normal)\n",
    "3. Overweight_Level_I   (Sobrepeso Nível I)\n",
    "4. Overweight_Level_II  (Sobrepeso Nível II)\n",
    "5. Obesity_Type_I       (Obesidade Tipo I)\n",
    "6. Obesity_Type_II      (Obesidade Tipo II)\n",
    "7. Obesity_Type_III     (Obesidade Tipo III - Mórbida)\n",
    "\n",
    "Essas classes foram convertidas numericamente (0 a 6) pelo LabelEncoder durante o\n",
    "pré-processamento e são revertidas para estes rótulos textuais na saída final.\n",
    "\"\"\"\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "BASE_DIR                        = Path.cwd().parent\n",
    "DATA_DIR                        = BASE_DIR / 'data'\n",
    "MODELS_DIR                      = BASE_DIR / 'models'\n",
    "CSV_FILE                        = DATA_DIR / 'Obesity.csv'\n",
    "CSV_PREDICTIONS_OUTPUT          = DATA_DIR / 'historico_predicoes_treino.csv'\n",
    "ENCODER_CLASSES_PATH            = MODELS_DIR / 'encoder_classes.pkl'\n",
    "MODELO_OBESIDADE_PATH           = MODELS_DIR / 'modelo_obesidade.pkl'\n",
    "\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def train_final_model():\n",
    "    print(\">>> Iniciando Pipeline de Treinamento (XGBoost)...\")\n",
    "        \n",
    "    # Foi carregado o dataset a partir do caminho especificado\n",
    "    df = pd.read_csv(CSV_FILE)\n",
    "    \n",
    "    # Foram removidas as linhas duplicadas para garantir a qualidade dos dados\n",
    "    df = df.drop_duplicates()\n",
    "    \n",
    "    # 2. Feature Engineering (Engenharia de Recursos)\n",
    "    print(\">>> Executando Engenharia de Features...\")\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Feature 1: BMI (Índice de Massa Corporal)\n",
    "    # ---------------------------------------------------------\n",
    "    # Lógica de Negócio: O fator clínico determinante para diagnóstico de obesidade segundo a OMS.\n",
    "    # Fórmula: Peso (kg) / Altura (m)²\n",
    "    df['BMI'] = df['Weight'] / (df['Height'] ** 2)\n",
    "    \n",
    "    # ---------------------------------------------------------\n",
    "    # Feature 2: Sedentary_Ratio (Razão de Sedentarismo)\n",
    "    # ---------------------------------------------------------\n",
    "    # Lógica de Negócio: Identificado o \"sedentarismo digital\" cruzando o tempo excessivo de tela\n",
    "    # com a baixa frequência de exercícios. Quanto maior o valor, maior o risco.\n",
    "    # Fórmula: TUE (Tempo Tecnologia) - FAF (Freq. Atividade Física)\n",
    "    df['Sedentary_Ratio'] = df['TUE'] - df['FAF']\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Feature 3: Hydration_Efficiency (Eficiência de Hidratação)\n",
    "    # ---------------------------------------------------------\n",
    "    # Lógica de Negócio: Relativiza o consumo de água pelo peso corporal. Pessoas mais pesadas \n",
    "    # precisam de mais água; o consumo absoluto engana o modelo.\n",
    "    # Fórmula: CH2O (Litros de Água) / Weight (Peso)\n",
    "    df['Hydration_Efficiency'] = df['CH2O'] / df['Weight']\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "    # Feature 4: Unhealthy_Score (Score de Hábitos Nocivos)\n",
    "    # ---------------------------------------------------------\n",
    "    # Lógica de Negócio: Foi criado um \"score de risco\" somando comportamentos negativos.\n",
    "    # Agrupa pequenos hábitos (fumar, comer calorias, álcool) em um indicador.\n",
    "    # Fórmula: (Fuma? 1:0) + (Comida Calórica? 1:0) + (Bebe Álcool? 1:0)\n",
    "    \n",
    "    # Mapeamento manual temporário para cálculo aritmético (antes do OneHotEncoder)\n",
    "    flag_smoke = (df['SMOKE'] == 'yes').astype(int)\n",
    "    flag_favc = (df['FAVC'] == 'yes').astype(int)\n",
    "    flag_calc = (df['CALC'] != 'no').astype(int) # Considera risco se beber \"às vezes\", \"frequentemente\" ou \"sempre\"\n",
    "    \n",
    "    df['Unhealthy_Score'] = flag_smoke + flag_favc + flag_calc\n",
    "\n",
    "    # ---------------------------------------------------------\n",
    "\n",
    "    # Foram separadas as variáveis preditoras (X) da variável alvo (y)\n",
    "    X = df.drop(columns=['Obesity'])\n",
    "    y = df['Obesity']\n",
    "    \n",
    "    # 3. Encoding do Target\n",
    "    # Foi instanciado e ajustado o LabelEncoder para transformar as classes em números\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    \n",
    "    # Foi salvo o encoder para permitir a decodificação das predições na aplicação final\n",
    "    joblib.dump(le, MODELS_DIR / 'encoder_classes.pkl')\n",
    "    \n",
    "    # 4. Configuração do Pipeline\n",
    "    # Foram identificadas automaticamente as colunas categóricas e numéricas\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    numeric_cols = X.select_dtypes(exclude=['object']).columns.tolist()\n",
    "    \n",
    "    # Foi configurado o pré-processador com padronização para numéricos e OneHot para categóricos\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numeric_cols),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "        ])\n",
    "    \n",
    "    # Foi estruturado o pipeline final integrando pré-processamento e o classificador XGBoost\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', XGBClassifier(\n",
    "            objective='multi:softmax',\n",
    "            num_class=len(le.classes_), # Foi definido automaticamente o nº de classes (7)\n",
    "            eval_metric='mlogloss',\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # 5. Treinamento Full\n",
    "    print(\">>> Treinando modelo com 100% dos dados e features...\")\n",
    "    # Foi executado o treinamento do modelo com a totalidade dos dados disponíveis\n",
    "    pipeline.fit(X, y_encoded)\n",
    "    \n",
    "    # 6. Geração de Resultados em CSV\n",
    "    print(\">>> Gerando arquivo de previsões para conferência...\")\n",
    "    \n",
    "    # Foram geradas as predições usando os próprios dados de treino para validação final\n",
    "    y_pred_encoded = pipeline.predict(X)\n",
    "    \n",
    "    # Foram revertidos os códigos numéricos para os rótulos originais\n",
    "    y_pred_labels = le.inverse_transform(y_pred_encoded)\n",
    "    \n",
    "    # Foi criado um DataFrame consolidado com os dados originais e a predição do modelo\n",
    "    df_results = df.copy()\n",
    "    df_results['Predicao_Modelo'] = y_pred_labels\n",
    "    \n",
    "    # Foi criada uma coluna booleana para verificar a assertividade de cada linha\n",
    "    df_results['Previsao_Correta'] = df_results['Obesity'] == df_results['Predicao_Modelo']\n",
    "    \n",
    "    # Foi salvo o arquivo CSV contendo o histórico das predições e a validação\n",
    "    df_results.to_csv(CSV_PREDICTIONS_OUTPUT, index=False)\n",
    "    \n",
    "    # 7. Serialização\n",
    "    # Foi serializado e salvo o pipeline treinado em formato .pkl\n",
    "    joblib.dump(pipeline, MODELO_OBESIDADE_PATH)\n",
    "    \n",
    "    print(\">>> Concluído! Arquivos gerados:\")\n",
    "    print(f\"    - {MODELO_OBESIDADE_PATH} (Pipeline Completo)\")\n",
    "    print(f\"    - {ENCODER_CLASSES_PATH} (Tradutor de Classes)\")\n",
    "    print(f\"    - {CSV_PREDICTIONS_OUTPUT} (Tabela com resultados e validação)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_final_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
